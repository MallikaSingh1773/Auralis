Auralis â€“ Your Personal AI Voice Assistant

Auralis is a lightweight, extensible AI voice assistant built using Python, Flask, speech recognition, and LLM-based intent handling. It listens to voice commands, understands the userâ€™s intent, and performs actions in real time â€” just like a mini Jarvis.

ğŸš€ Features

ğŸ™ Real-time Speech Recognition
Converts voice to text with high accuracy.

ğŸ§  Intent Understanding using LLM
Detects what the user wants (open apps, search, respond, etc.).

âš™ï¸ Action Execution
Performs system operations based on user commands.

ğŸ” Interactive Backend + Frontend Sync
Flask backend + clean frontend interface.

ğŸ—‚ Modular Code Structure
Easy to expand with new features or custom commands.

ğŸ›  Tech Stack

Backend:

Python

Flask

SpeechRecognition

PyAudio

LLM integration (OpenAI / custom model)

Frontend:

HTML/CSS/JS

Simple clean UI for displaying responses

ğŸ“‚ Project Structure
Auralis/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ auth/
â”‚   â”œâ”€â”€ ... (API & processing)
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ scripts.js
â”‚
â”œâ”€â”€ main.py
â”œâ”€â”€ run.py
â””â”€â”€ README.md

â–¶ï¸ How to Run the Project
1. Clone the Repo
git clone https://github.com/MallikaSingh1773/Auralis.git
cd Auralis

2. Install Dependencies
pip install -r requirements.txt

3. Start the Backend
python run.py

4. Open the Frontend

Go to:

http://localhost:5000

ğŸ§© How It Works (Pipeline)

Voice â†’ Text â†’ Intent â†’ Action â†’ Response

User speaks a command

Auralis converts speech to text

LLM detects the intent

System performs the action

Response is shown on UI

ğŸ§± Future Improvements

Add RAG-based knowledge responses

Add integration with smart devices

Web-based control panel

Emotion-aware responses

Replace speech-recognition with Whisper for accuracy

ğŸ¤ Contributing

Pull requests are welcome!
If you want to improve features or add new actions, feel free.

ğŸ“„ License

This project is open-source under the MIT License.
