# Auralis â€“ Personal AI Voice Assistant

Auralis is a personal AI voice assistant that listens to commands, understands user intent, and performs actions in real time. It is built using Python, Flask, speech recognition, and LLM-based intent processing. The goal of Auralis is to provide a lightweight â€œJarvis-likeâ€ assistant that can be extended easily.

---

## ğŸš€ Features
- ğŸ™ Real-time speech recognition  
- ğŸ§  LLM-based intent understanding  
- âš™ï¸ Executes system-level actions  
- ğŸŒ Flask backend + simple frontend UI  
- ğŸ›  Modular and easy to extend  

---

## ğŸ›  Tech Stack
**Backend**
- Python  
- Flask  
- SpeechRecognition & PyAudio  
- OpenAI/LLM integration  

**Frontend**
- HTML, CSS, JavaScript  

---

## ğŸ“ Project Structure
Auralis/
â”‚
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ auth/
â”‚ â”œâ”€â”€ (API + intent logic)
â”‚
â”œâ”€â”€ frontend/
â”‚ â”œâ”€â”€ index.html
â”‚ â”œâ”€â”€ script.js
â”‚
â”œâ”€â”€ main.py
â”œâ”€â”€ run.py
â””â”€â”€ README.md


## â–¶ï¸ How to Run

### 1. Clone the repository
```bash
git clone https://github.com/MallikaSingh1773/Auralis.git
cd Auralis
2. Install dependencies
bash
Copy code
pip install -r requirements.txt
3. Run the backend
bash
Copy code
python run.py
4. Open the app
Go to:

arduino
Copy code
http://localhost:5000
ğŸ”„ How Auralis Works
Voice â†’ Speech-to-Text â†’ Intent Detection â†’ Action â†’ Response

User speaks

Auralis converts speech to text

LLM detects the userâ€™s intent

Backend performs the required action

Response is shown in UI

ğŸ“Œ Future Enhancements
Better speech accuracy (Whisper)

Add RAG for contextual knowledge

Add more voice commands

Build a dashboard UI

Add mobile support

ğŸ¤ Contributing
Pull requests and suggestions are welcome.


